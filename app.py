# -*- coding: utf-8 -*-
# ===========================================================
# AI-Deal-Checker â€“ ×’×¨×¡×” ×œ×•××“×ª (Gemini 2.5 Flash)
# ×›×•×œ×œ × ×™×ª×•×— ×¢×§×‘×™×•×ª, 18 ××§×¨×™ ×§×¦×”, ×ª×™×§×•×Ÿ JSON ×•×©××™×¨×” ×œ-Google Sheets
# ===========================================================

import streamlit as st
import google.generativeai as genai
import json, os, traceback, requests
from json_repair import repair_json
from PIL import Image
import pandas as pd
from datetime import datetime

# ---------- ×”×’×“×¨×•×ª ×›×œ×œ×™×•×ª ----------
st.set_page_config(page_title="AI Deal Checker ğŸš—", page_icon="ğŸš—", layout="centered")

# ---------- ×—×™×‘×•×¨ ×œ××•×“×œ ----------
api_key = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.5-flash")

SHEET_ID = st.secrets.get("SHEET_ID", None)
SHEET_NAME = "data"
SHEETS_URL = f"https://sheets.googleapis.com/v4/spreadsheets/{SHEET_ID}/values/{SHEET_NAME}!A1:append?valueInputOption=RAW&key={st.secrets.get('GOOGLE_SHEETS_API_KEY')}"

HISTORY_FILE = "data_history.json"

# ---------- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ----------
def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_to_history(entry):
    history = load_history()
    history.append(entry)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def get_model_avg(brand, model_name):
    history = load_history()
    scores = [h["deal_score"] for h in history if h["from_ad"].get("brand") == brand and model_name in h["from_ad"].get("model", "")]
    return round(sum(scores) / len(scores), 2) if scores else None

def check_consistency(brand, model_name):
    history = load_history()
    relevant = [h["deal_score"] for h in history if h["from_ad"].get("brand") == brand and model_name in h["from_ad"].get("model", "")]
    if len(relevant) >= 3:
        diff = max(relevant) - min(relevant)
        if diff >= 25:
            return True, relevant
    return False, relevant

def save_to_sheets(entry):
    if not SHEET_ID:
        return
    try:
        data = {
            "values": [[
                datetime.now().strftime("%Y-%m-%d %H:%M"),
                entry["from_ad"].get("brand", ""),
                entry["from_ad"].get("model", ""),
                entry["from_ad"].get("year", ""),
                entry["deal_score"],
                entry["classification"],
                entry["from_ad"].get("price_nis", ""),
                entry["short_verdict"]
            ]]
        }
        requests.post(SHEETS_URL, json=data)
    except Exception as e:
        print("Google Sheets save error:", e)

# ---------- ×××©×§ ----------
st.title("ğŸš— AI Deal Checker â€“ ×‘×“×™×§×ª ×›×“××™×•×ª ×—×›××” ×•×œ×•××“×ª")
st.write("×”×¢×ª×§ ××ª ×˜×§×¡×˜ ×”××•×“×¢×” (×›×•×œ×œ ××—×™×¨, ×©× ×”, ×§×´× ×•×›×•×³) ×•×”×¢×œ×” ×ª××•× ×•×ª ×©×œ ×”×¨×›×‘ ×œ×‘×™×¦×•×¢ ×”×¦×œ×‘×” ×‘×™×Ÿ × ×ª×•× ×™ ×”××•×“×¢×” ×œ× ×ª×•× ×™ ×”×©×•×§ ×‘×¤×•×¢×œ:")

ad_text = st.text_area("ğŸ“‹ ×”×“×‘×§ ×›××Ÿ ××ª ×˜×§×¡×˜ ×”××•×“×¢×”:", height=250)
uploaded_images = st.file_uploader("ğŸ“¸ ×”×¢×œ×” ×ª××•× ×•×ª ×©×œ ×”×¨×›×‘ (× ×™×ª×Ÿ ×œ×‘×—×•×¨ ×›××”):", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

st.markdown(
    """
    <div style='background-color:#fff3cd; border-radius:10px; padding:10px; border:1px solid #ffeeba;'>
    âš ï¸ <b>×”×‘×”×¨×”:</b> × ×™×ª×•×— ×–×” ××‘×•×¡×¡ ×‘×™× ×” ××œ××›×•×ª×™×ª ×•××™× ×• ×ª×—×œ×™×£ ×œ×‘×“×™×§×” ××§×¦×•×¢×™×ª.
    ×™×© ×œ×‘×§×© ×”×™×¡×˜×•×¨×™×™×ª ×˜×™×¤×•×œ×™× ××œ××” ×•×œ×”×•×¦×™× ×“×•×´×— ×¢×‘×¨ ×‘×™×˜×•×—×™ ×œ×¤× ×™ ×¨×›×™×©×”.
    </div>
    """,
    unsafe_allow_html=True
)

# ---------- ×¤×¢×•×œ×” ----------
if st.button("×—×©×‘ ×¦×™×•×Ÿ ×›×“××™×•×ª"):
    if not ad_text.strip() and not uploaded_images:
        st.error("×× × ×”×“×‘×§ ×˜×§×¡×˜ ××• ×”×¢×œ×” ×œ×¤×—×•×ª ×ª××•× ×” ××—×ª.")
    else:
        with st.spinner("ğŸ” ××‘×¦×¢ ×”×¦×œ×‘×” ×—×›××” ×‘×™×Ÿ × ×ª×•× ×™ ×”××•×“×¢×” ×œ× ×ª×•× ×™ ×”×©×•×§..."):
            try:
                # ---------- ×©×œ×‘ ×™×¦×™×‘×•×ª ----------
                possible_brand = ad_text.split(" ")[0] if ad_text else ""
                consistency_alert, prev_scores = check_consistency(possible_brand, ad_text)
                stability_note = ""
                if consistency_alert:
                    stability_note = f"âš ï¸ ×–×•×”×ª×” ××™-×¢×§×‘×™×•×ª ×‘×™×Ÿ ×¦×™×•× ×™× ×§×•×“××™×: {prev_scores}. ×× × ×—×–×§ ××ª ×”×™×¦×™×‘×•×ª ×©×œ ×”× ×™×ª×•×—."

                # ---------- ×¤×¨×•××¤×˜ ××œ× ----------
                prompt = f"""
××ª×” ×× ×œ×™×¡×˜ ××•××—×” ×œ×©×•×§ ×”×¨×›×‘ ×”×™×©×¨××œ×™. ×¢×œ×™×š ×œ×”×¢×¨×™×š ××ª ×›×“××™×•×ª ×”×¢×¡×§×” ×©×œ ×¨×›×‘ ××©×•××© ×œ×¤×™ ×˜×§×¡×˜ ×”××•×“×¢×” ×•×”×ª××•× ×•×ª ×”××¦×•×¨×¤×•×ª.

×× ×§×™×‘×œ×ª ××–×”×¨×” ×¢×œ ×—×•×¡×¨ ×¢×§×‘×™×•×ª ×§×•×“××ª, ×§×— ×–××ª ×‘×—×©×‘×•×Ÿ ×•×™×™×¦×¨ ×¦×™×•×Ÿ ×××•×–×Ÿ ×™×•×ª×¨ ×‘×”×ª×‘×¡×¡ ×¢×œ ××’××•×ª ×¢×‘×¨:
{stability_note}

×¡×¤×§ × ×™×ª×•×— ××“×•×™×§, ×¨×™××œ×™ ×•××‘×•×¡×¡ ×¢×•×‘×“×•×ª.

---
ğŸ”¹ ×©×œ×‘ 1 â€“ × ×™×ª×•×— ××•×“×¢×”
×§×¨× ××ª ×”××•×“×¢×”:
\"\"\"{ad_text}\"\"\"
×”×¤×§ ××× ×” ××ª ×”× ×ª×•× ×™× (×™×¦×¨×Ÿ, ×“×’×, ×’×¨×¡×”, ×©× ×”, ××—×™×¨, ×§×´×, ×“×œ×§, ×™×“, ××–×•×¨, ×˜×¡×˜, ×˜×™×¤×•×œ×™× ×•×›×•×³)
×•×¦×™×™×Ÿ ××™×œ×• ×”×•×¤×§×• ××”××•×“×¢×”.

---
ğŸ”¹ ×©×œ×‘ 2 â€“ × ×ª×•× ×™ ×©×•×§
××¦× ××™×“×¢ ×¢×“×›× ×™ ×¢×œ ×”×“×’×:
××—×™×¨ ×©×•×§ ×××•×¦×¢, ×××™× ×•×ª, ×¢×œ×•×ª ×ª×—×–×•×§×”, ×ª×§×œ×•×ª ×™×“×•×¢×•×ª, ×‘×™×§×•×© ×•×‘×˜×™×—×•×ª.

---
ğŸ”¹ ×©×œ×‘ 3 â€“ ×”×¦×œ×‘×”
×”×©×•×•×” ×‘×™×Ÿ ×”× ×ª×•× ×™× ××”××•×“×¢×” ×œ× ×ª×•× ×™ ×”×©×•×§, ×•×¦×™×™×Ÿ ×¤×¢×¨×™×, ×™×ª×¨×•× ×•×ª ×•×¡×™×›×•× ×™×.

---
ğŸ”¹ ×©×œ×‘ 4 â€“ ×©×™×§×•×œ×™ ×–×”×™×¨×•×ª
×”×•×¨×“ ×¦×™×•×Ÿ ×¨×§ ×× ×§×™×™××™× ×¡×™×›×•× ×™× ×××©×™×™×:
- ××—×™×¨ × ××•×š ×‘Ö¾15%+ ×œ×œ× ×¡×™×‘×”
- ×”×™×¢×“×¨ ×”×™×¡×˜×•×¨×™×™×ª ×˜×™×¤×•×œ×™×
- ×§×´× ×’×‘×•×” ×××•×“
- ×™×“ 4+
- ×¨×›×‘ ×œ×™×¡×™× ×’ ×œ× ××˜×•×¤×œ
- ×˜×•×¨×‘×• ×™×©×Ÿ
- ×’×™×¨ ×¨×•×‘×•×˜×™ ×™×©×Ÿ
- ×—×©××œ×™ ×¢× ×¡×•×œ×œ×” ×œ× × ×‘×“×§×”
- ×¨×›×‘ ×™×©×Ÿ ×¢× ×ª×—×–×•×§×” ×™×§×¨×”

---
ğŸ”¹ ×©×œ×‘ 4.5 â€“ 18 ××§×¨×™ ×§×¦×”
1. ×§×´× ×’×‘×•×” ×¢× ×˜×™×¤×•×œ×™× = ×ª×§×™×Ÿ.
2. ××—×™×¨ × ××•×š ×¢×“ 10% = ×œ× ×—×©×•×“.
3. ××—×™×¨ ×’×‘×•×” ××•×¦×“×§ ×× ×’×¨×¡×” ×××•×‘×–×¨×ª.
4. ×¨×›×‘×™ ×©×˜×— â€“ ×§×´× ×’×‘×•×” × ×•×¨××œ×™.
5. ×¨×›×‘×™ × ×™×©×” â€“ ×œ× ×œ××“×•×“ ×œ×¤×™ ×‘×™×§×•×©.
6. × ×™×¡×•×— ×¨×©×œ× ×™ â€“ ×œ× ×©×œ×™×œ×”.
7. ××•×“×¢×” ×§×¦×¨×” â€“ ×”×©×œ× ××™×“×¢.
8. ××—×™×¨ × ××•×š ×‘Ö¾50% = ×—×©×“ ×”×©×‘×ª×”.
9. ×™×‘×•× ××™×©×™ â€“ ××œ ×ª×©×•×•×” ×œ×©×•×§ ×¨×’×™×œ.
10. ××¡×¤× ×•×ª â€“ ×’×™×œ ×œ× ×—×™×¡×¨×•×Ÿ.
11. ×¡×•×—×¨ â€“ ×”×¤×—×ª ×××™× ×•×ª.
12. â€œ××—×™×¨ ×¡×•×¤×™â€ â€“ ×œ× ×‘×”×›×¨×— ×—×©×•×“.
13. ×¦×‘×¢ ×—×¨×™×’ â€“ ×× ××§×•×¨×™ ×œ× ×—×™×¡×¨×•×Ÿ.
14. ××™×Ÿ ×§×´× â€“ ×”×¢×¨×š ×××•×¦×¢.
15. ××–×•×¨ ×œ×— â€“ ×¡×™×›×•×Ÿ ×—×œ×•×“×”.
16. ×—×¡×¨ ××—×™×¨ â€“ ×”×¢×¨×š ×œ×¤×™ ×˜×•×•×— ×“×’×.
17. ×œ×™×¡×™× ×’ ×©×˜×•×¤×œ â€“ ×ª×§×™×Ÿ.
18. ×©×¤×” ×–×¨×” â€“ ×”×¡×ª××š ×¢×œ × ×ª×•× ×™× ×‘×œ×‘×“.

---
ğŸ”¹ ×©×œ×‘ 5 â€“ × ×•×¡×—×ª ×¦×™×•×Ÿ (0â€“100)
- ××—×™×¨ ××•×œ ×©×•×§ â€“ 25%
- ×ª×—×–×•×§×” ×•××¦×‘ â€“ 25%
- ×××™× ×•×ª ×“×’× â€“ 20%
- ×’×™×œ ×•×§×´× â€“ 15%
- ×××™× ×•×ª ××•×›×¨ â€“ 10%
- ×‘×™×§×•×© â€“ 5%

---
ğŸ”¹ ×©×œ×‘ 6 â€“ ×¤×œ×˜ JSON ×‘×œ×‘×“
{{
  "from_ad": {{
    "brand": "",
    "model": "",
    "year": 0,
    "mileage_km": 0,
    "price_nis": 0,
    "ad_claims": []
  }},
  "from_internet": {{
    "market_estimate_nis": 0,
    "reliability_score": 0,
    "avg_maintenance_cost": 0,
    "demand_level": "",
    "known_issues": []
  }},
  "cross_analysis": {{
    "price_alignment": "",
    "condition_alignment": "",
    "key_differences": []
  }},
  "deal_score": 0,
  "classification": "",
  "short_verdict": "",
  "key_reasons": [],
  "user_info": {{
    "reliability_summary": "",
    "maintenance_tips": [],
    "common_faults": [],
    "market_context": ""
  }}
}}
---

ğŸ”¹ ×©×œ×‘ 7 â€“ ×ª×™×§×•×Ÿ ×©×•×§
×× ×§×™×™××ª ×”×™×¡×˜×•×¨×™×” ×œ×“×’× ×–×”, ×”×©×•×•×” ×œ×¦×™×•× ×™× ×”×§×•×“××™×:
- ×× ×”×¤×¢×¨ ××¢×œ 15 × ×§×³, ×‘×¦×¢ ×ª×™×§×•×Ÿ ×©×œ 50% ×œ×›×™×•×•×Ÿ ×”×××•×¦×¢.
"""

                # ---------- ×§×¨×™××” ×œ××•×“×œ ----------
                inputs = [prompt]
                for img in uploaded_images:
                    inputs.append(Image.open(img))
                response = model.generate_content(inputs, request_options={"timeout": 120})
                fixed_json = repair_json(response.text)
                data = json.loads(fixed_json)

                # ---------- ×ª×™×§×•×Ÿ ×©×•×§ ----------
                avg = get_model_avg(data["from_ad"]["brand"], data["from_ad"]["model"])
                if avg:
                    diff = data["deal_score"] - avg
                    if abs(diff) >= 15:
                        correction = -diff * 0.5
                        data["deal_score"] = int(data["deal_score"] + correction)
                        data["short_verdict"] += f" âš™ï¸ (×‘×•×¦×¢ ×ª×™×§×•×Ÿ ×§×œ ×œ×¤×™ ×××•×¦×¢ ×”×™×¡×˜×•×¨×™: {avg})"

                # ---------- ×©××™×¨×” ----------
                save_to_history(data)
                save_to_sheets(data)

                # ---------- ×ª×¦×•×’×” ----------
                score = data["deal_score"]
                color = "#28a745" if score >= 80 else "#ffc107" if score >= 60 else "#dc3545"
                st.markdown(f"<h3 style='color:{color}'>ğŸš¦ ×¦×™×•×Ÿ ×›×“××™×•×ª ×›×•×œ×œ: {score}/100 â€” {data['classification']}</h3>", unsafe_allow_html=True)
                st.write("ğŸ§¾ **×¡×™×›×•×:**", data["short_verdict"])
                st.divider()
                st.subheader("ğŸ“‹ × ×ª×•× ×™× ××ª×•×š ×”××•×“×¢×”:")
                st.json(data["from_ad"])
                st.subheader("ğŸŒ × ×ª×•× ×™ ×©×•×§ ×©× ××¦××• ×‘××™× ×˜×¨× ×˜:")
                st.json(data["from_internet"])
                st.subheader("ğŸ” ×”×¦×œ×‘×” ×•× ×™×ª×•×— ×¤×¢×¨×™×:")
                st.json(data["cross_analysis"])
                st.subheader("ğŸ§  ×¡×™×‘×•×ª ×¢×™×§×¨×™×•×ª ×œ×¦×™×•×Ÿ:")
                for r in data["key_reasons"]:
                    st.write(f"â€¢ {r}")
                st.divider()
                st.subheader("ğŸ“š ××™×“×¢ × ×•×¡×£ ×œ××©×ª××©")
                info = data.get("user_info", {})
                if info:
                    st.write(f"**×××™× ×•×ª ×”×“×’×:** {info.get('reliability_summary', '×œ× ×¦×•×™×Ÿ')}")
                    if info.get("common_faults"):
                        st.write("**×ª×§×œ×•×ª × ×¤×•×¦×•×ª:**")
                        for f in info["common_faults"]:
                            st.write(f"â€¢ {f}")
                    if info.get("maintenance_tips"):
                        st.write("**×˜×™×¤×™× ×œ×ª×—×–×•×§×”:**")
                        for tip in info["maintenance_tips"]:
                            st.write(f"â€¢ {tip}")
                    if info.get("market_context"):
                        st.write("**×”×§×©×¨ ×©×•×§ ×›×œ×œ×™:**", info["market_context"])

                # ---------- ×’×¨×£ ××’××” ----------
                history = load_history()
                model_entries = [h for h in history if h["from_ad"]["brand"] == data["from_ad"]["brand"] and data["from_ad"]["model"] in h["from_ad"]["model"]]
                if len(model_entries) >= 2:
                    df = pd.DataFrame([{"Index": i + 1, "Score": h["deal_score"]} for i, h in enumerate(model_entries)])
                    st.line_chart(df.set_index("Index"), height=200)
                    st.caption("ğŸ“ˆ ××’××ª ×¦×™×•× ×™× ×”×™×¡×˜×•×¨×™×ª ×œ×“×’× ×–×”")

                st.caption("Â© 2025 Car Advisor AI â€“ ×’×¨×¡×” ×œ×•××“×ª ×¢× ×ª×™×§×•×Ÿ ×©×•×§ ×•××§×¨×™ ×§×¦×” ××œ××™×")

            except Exception as e:
                st.error("âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×¤×œ×˜ ××• ×‘×§×¨×™××ª ×”××™×“×¢ ××”××•×“×œ.")
                st.code(traceback.format_exc())